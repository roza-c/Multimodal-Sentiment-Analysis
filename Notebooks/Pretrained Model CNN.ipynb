{"cells":[{"cell_type":"markdown","metadata":{"id":"-m7auONinCbt"},"source":["# Importing and preprocessing images"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KLFqF_3RM2QQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712446310382,"user_tz":240,"elapsed":1823,"user":{"displayName":"Roza Cicek","userId":"09114837280913358755"}},"outputId":"b252a065-ac3f-4f87-c5ee-cfefd1b7a16c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ye7m2Nk0NCHs","executionInfo":{"status":"ok","timestamp":1712446341759,"user_tz":240,"elapsed":30118,"user":{"displayName":"Roza Cicek","userId":"09114837280913358755"}}},"outputs":[],"source":["from torchvision import transforms, datasets\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((244, 244))\n","])\n","\n","# Create an ImageFolder instance aka a dataloader\n","dataset = datasets.ImageFolder('/content/drive/My Drive/APS360 Group/Data preprocessing/Image data', transform=transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7CYOCmEVCm9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710778150119,"user_tz":240,"elapsed":204,"user":{"displayName":"Roza Cicek","userId":"09114837280913358755"}},"outputId":"540bb53c-b256-436c-f96b-0dd62c79c976"},"outputs":[{"output_type":"stream","name":"stdout","text":["len train_loader  181\n","len val_loader  23\n","len test_loader  23\n"]}],"source":["import numpy as np\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch\n","\n","batch_size = 64\n","\n","# Shuffle and split the training set from the rest\n","np.random.seed(1000)\n","indices = list(range(len(dataset)))  # Generate indices for the entire dataset\n","np.random.shuffle(indices)\n","split_train = int(len(indices) * 0.8)  # 80-20 split\n","train_indices, test_val_indices = indices[:split_train], indices[split_train:]\n","\n","# Shuffle and split the rest into testing and validation sets\n","np.random.shuffle(test_val_indices)\n","split_test_val = int(len(test_val_indices) * 0.5)  # 50-50 split\n","test_indices, val_indices = test_val_indices[:split_test_val], test_val_indices[split_test_val:]\n","\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=1)\n","print(\"len train_loader \", len(train_loader))\n","\n","val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, num_workers=1)\n","print(\"len val_loader \", len(val_loader))\n","\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=1)\n","print(\"len test_loader \", len(test_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoM2oYRUl6s_"},"outputs":[],"source":["# Continue from your previous code to calculate the standard deviation\n","channel_sum, channel_squared_sum, num_batches = 0, 0, 0\n","for data, _ in train_loader:\n","    channel_sum += torch.mean(data, dim=[0, 2, 3])\n","    channel_squared_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n","    num_batches += 1\n","\n","mean = channel_sum / num_batches\n","std_dev = (channel_squared_sum / num_batches - mean ** 2) ** 0.5\n","\n","print(f'Mean per channel: {mean}')\n","print(f'Standard deviation per channel: {std_dev}')"]},{"cell_type":"markdown","metadata":{"id":"EUNgvlXBoYmZ"},"source":["Now that we have the normalization and standard deviation values, we can compute the final train, test and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePaPKr29of89"},"outputs":[],"source":["from torchvision import transforms, datasets\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((244, 244)),\n","    transforms.Normalize(mean=[0.4373, 0.4091, 0.3735], std=[0.2990, 0.2863, 0.2986])\n","])\n","\n","# Create an ImageFolder instance aka a dataloader\n","dataset = datasets.ImageFolder(root='/content/drive/My Drive/APS360 Group/Data preprocessing/Image data', transform=transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZIUPD0qoXdi","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"error","timestamp":1710908433394,"user_tz":240,"elapsed":8714,"user":{"displayName":"Roza Cicek","userId":"09114837280913358755"}},"outputId":"648e6bdb-196f-4eed-dd1f-9869f8991b72"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1b501eb066ac>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Shuffle and split the training set from the rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Generate indices for the entire dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msplit_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 80-20 split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}],"source":["import numpy as np\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch\n","\n","batch_size = 64\n","\n","# Shuffle and split the training set from the rest\n","np.random.seed(1000)\n","indices = list(range(len(dataset)))  # Generate indices for the entire dataset\n","np.random.shuffle(indices)\n","split_train = int(len(indices) * 0.8)  # 80-20 split\n","train_indices, test_val_indices = indices[:split_train], indices[split_train:]\n","\n","# Shuffle and split the rest into testing and validation sets\n","np.random.shuffle(test_val_indices)\n","split_test_val = int(len(test_val_indices) * 0.5)  # 50-50 split\n","test_indices, val_indices = test_val_indices[:split_test_val], test_val_indices[split_test_val:]\n","\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=1)\n","print(\"len train_loader \", len(train_loader))\n","\n","val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, num_workers=1)\n","print(\"len val_loader \", len(val_loader))\n","\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=1)\n","print(\"len test_loader \", len(test_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9IHCsUFT4IT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","k = 0\n","for images, labels in train_loader:\n","    # since batch_size = 1, there is only 1 image in `images`\n","    image = images[0]\n","    print(\"shape of image \", image.shape)\n","    # place the colour channel at the end, instead of at the beginning\n","    img = np.transpose(image, [1,2,0])\n","    # normalize pixel intensity values to [0, 1]\n","    img = img / 2 + 0.5\n","    plt.subplot(3, 5, k+1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","    k += 1\n","    if k > 14:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"z32f6stonIE-"},"source":["# Coding the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzntA4Tp2Bl_","executionInfo":{"status":"ok","timestamp":1710780121122,"user_tz":240,"elapsed":952,"user":{"displayName":"Roza Cicek","userId":"09114837280913358755"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7f9d9e8-832e-4242-a250-aab516b03d31"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 97.4MB/s]\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torchvision.models as models\n","\n","# Load pretrained ResNet18 model\n","pretrained_model = models.resnet18(pretrained=True)\n","\n","# Freeze all layers in the pretrained model\n","for param in pretrained_model.parameters():\n","    param.requires_grad = False\n","\n","# Modify the last layer to fit your task (change number of output classes)\n","num_ftrs = pretrained_model.fc.in_features\n","pretrained_model.fc = nn.Linear(num_ftrs, 3)  # Assuming 3 classes: Negative, Neutral, Positive\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(pretrained_model.parameters(), lr=0.001)\n","\n","# Define device to run the model on (GPU if available, otherwise CPU)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","pretrained_model = pretrained_model.to(device)"]},{"cell_type":"code","source":["# Training function\n","def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n","    train_loss_history = []\n","    train_acc_history = []\n","    val_loss_history = []\n","    val_acc_history = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","\n","        train_loss = running_loss / len(train_loader)\n","        train_accuracy = correct_train / total_train\n","        train_loss_history.append(train_loss)\n","        train_acc_history.append(train_accuracy)\n","\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                total_val += labels.size(0)\n","                correct_val += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(val_loader)\n","        val_accuracy = correct_val / total_val\n","        val_loss_history.append(val_loss)\n","        val_acc_history.append(val_accuracy)\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n","\n","    return train_loss_history, train_acc_history, val_loss_history, val_acc_history"],"metadata":{"id":"c5avI_qmEmfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 100\n","train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(pretrained_model, criterion, optimizer, train_loader, val_loader, num_epochs=num_epochs)"],"metadata":{"id":"8TMr3-vsTPHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training and validation curves\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(range(1, num_epochs+1), train_loss_history, label='Train')\n","plt.plot(range(1, num_epochs+1), val_loss_history, label='Validation')\n","plt.title('Loss Curves')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(range(1, num_epochs+1), train_acc_history, label='Train')\n","plt.plot(range(1, num_epochs+1), val_acc_history, label='Validation')\n","plt.title('Accuracy Curves')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"v9aoyH1aTSAW"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Hknkq2Jasq4bzGxhsb4YbhCFayllmXrx","timestamp":1710777012814}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}